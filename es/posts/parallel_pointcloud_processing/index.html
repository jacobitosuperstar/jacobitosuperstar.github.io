<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN crossorigin=anonymous><link href=//jacobobedoya.com/css/main.min.fdab6cf2d7feda06308d57d2ae5622a83a9852053cf73f19674bead9c36a1b8c.css rel=stylesheet><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700;900&display=swap" rel=stylesheet><link rel="shortcut icon" href=//jacobobedoya.com/favicon/favicon-310.0527484c8987eb011a0aaa843c590be2887b5e7f3b59e22677664aceac0b0b88.png><link rel=icon type=image/png href=//jacobobedoya.com/favicon/favicon-310.0527484c8987eb011a0aaa843c590be2887b5e7f3b59e22677664aceac0b0b88.png><link rel=apple-touch-icon type=image/png href=//jacobobedoya.com/favicon/favicon-310.0527484c8987eb011a0aaa843c590be2887b5e7f3b59e22677664aceac0b0b88.png><meta name=msapplication-config content="favicon/browserconfig.xml"><title>jacobitosuperstar
</title><meta name=description content="Personal page for my blog, CV and other posts that I wish to share in the page"></head><body><header id=header class=site-header role=banner><nav class="navbar navbar-expand-md navbar-dark justify-content-center fixed-top" style=background-color:#000><div class=container><a href=//jacobobedoya.com/es/ class="navbar-brand nav-link text-wrap" style=color:salmon onmouseover='this.style.color="red"' onmouseout='this.style.color="salmon"'><b>jacobitosuperstar</b>
</a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarToggler aria-controls=navbarToggler aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarToggler><ul class="navbar-nav nav-justified w-100 text-center" style=vertical-align:middle;text-transform:uppercase><li class=nav-item><div class=container><a href=//jacobobedoya.com/es/posts/ class="navbar-brand nav-link text-wrap" style=color:pink onmouseover='this.style.color="salmon"' onmouseout='this.style.color="pink"'><b>POSTS</b></a></div></li><li class=nav-item><div class=container><a href=//jacobobedoya.com/es/stories/ class="navbar-brand nav-link text-wrap" style=color:pink onmouseover='this.style.color="salmon"' onmouseout='this.style.color="pink"'><b>HISTORIAS</b></a></div></li><li class=nav-item><div class=container><a href=//jacobobedoya.com/es/about_me/ class="navbar-brand nav-link text-wrap" style=color:pink onmouseover='this.style.color="salmon"' onmouseout='this.style.color="pink"'><b>ACERCA DE M√ç</b></a></div></li><li class=nav-item><div class=container><a href=//jacobobedoya.com/es/cv/ class="navbar-brand nav-link text-wrap" style=color:pink onmouseover='this.style.color="salmon"' onmouseout='this.style.color="pink"'><b>CV</b></a></div></li><li class=nav-item><div class=container><div class=dropdown><button class="btn btn-secondary dropdown-toggle" type=button data-bs-toggle=dropdown aria-expanded=false>
es</button><ul class=dropdown-menu><li><a href=//jacobobedoya.com/en/posts/parallel_pointcloud_processing/ class=dropdown-item>English</a></li></ul></div></div></li></ul></div></div></nav></header><main><div class=container><h1 style=text-align:left;text-transform:uppercase>Python Parallelism for Point Cloud Processing</h1><p style=text-align:justify><p>LAS and its compressed counterpart LAZ are popular file formats for storing
Point Cloud information, typically generated by LiDAR technology. LiDAR, or
Light Detection and Ranging, is a remote sensing technology used to measure
distances and create highly accurate 3D maps of objects and landscapes. The
Point Cloud information stored mainly consists of X, Y, and Z coordinates,
intensity, color, feature classification, GPS time, and other custom fields
provided by the scanner. LAS files comprise millions of points that accurately
describe the sensed environment or object, making their analysis a challenging
task.</p><p>One of the fundamental steps in processing and analyzing 3D data is calculating
the normals. Normals in the Point Cloud provide information about the
orientation and direction of a surface at each point in the point cloud. This
information is essential for visualization, object recognition, and shape
analysis.</p><p>We won&rsquo;t delve into the details of how these normals are calculated or which
package to use for it. Instead, the focus of this article is to demonstrate how
to perform parallel calculations while chunked reading and chunked writing of a
LAS/LAZ file, and how Python manages the challenges of concurrency and
parallelism.</p><p>To follow along, you should have a general knowledge of Python and be familiar
with <code>numpy</code> and <code>laspy</code>. This article provides a high-level overview of
parallelism in Python.</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span>[packages]
</span></span><span style=display:flex><span>numpy = <span style=color:#79a8ff>&#34;==1.26.0&#34;</span>
</span></span><span style=display:flex><span>laspy = {extras = [<span style=color:#79a8ff>&#34;lazrs&#34;</span>], version = <span style=color:#79a8ff>&#34;==2.5.1&#34;</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[requires]
</span></span><span style=display:flex><span>python_version = <span style=color:#79a8ff>&#34;3.10&#34;</span>
</span></span></code></pre></div><p>Both <code>laspy</code> and <code>numpy</code> are packages that directly interact with the Python
C_API, making them extremely fast. There isn&rsquo;t much room for improvement in
terms of speed without resorting to direct C programming. Therefore, we need to
explore new ways to work with our code to enable parallelism or enhance
processing pipelines to utilize our machine&rsquo;s full potential.</p><p>As you may or may not know, Python execution is constrained by the Global
Interpreter Lock (GIL). The GIL is a mechanism used by the CPython Interpreter
to ensure that only one thread at a time executes Python bytecode. This
simplifies implementation and makes the object model of CPython safe against
concurrent access. While the GIL offers simplicity and benefits for
multithreaded programs and single-core, single-process performance, it raises
questions: Why use multithreading if multiple threads cannot execute
simultaneously? Is it possible to execute code in parallel with Python?</p><p>Multithreading is a means of making Python non-blocking, allowing us to create
code that initiates multiple tasks concurrently, even though only one task can
execute at any given moment. This type of concurrency is useful when making
calls to external APIs or databases where you spend most of the time waiting.
However, for CPU-intensive tasks, this approach has limitations.</p><p>To run Python code in parallel, the <code>multiprocessing</code> library spawns separate
processes on different cores using operating system API calls.</p><p><strong>spawn</strong> is the default method in MacOS and Windows. It creates child
processes that inherit the resources needed to run the object&rsquo;s <code>run()</code> method.
Although slower than other methods (like fork), it provides consistent
execution.</p><p><strong>fork</strong> is the default method in all POSIX systems except MacOS. It creates
child processes with all the context and resources of the parent process. It&rsquo;s
faster than <strong>spawn</strong>, but may encounter issues in multiprocess and
multithreaded environments.</p><p>This approach allows us to have a new Python interpreter for each processor,
eliminating the problem of multiple threads contending for the interpreter&rsquo;s
availability.</p><p>Given that Point Cloud processing is heavily reliant on CPU performance, we
employ multiprocessing to execute processes in parallel for each chunk of the
Point Cloud being read.</p><p>To read large LAS/LAZ files, <code>laspy</code> provides the <code>chunk_iterator</code> for reading
the Point Cloud in chunks of data that can be sent to different processes for
processing. Subsequently, the processed data is assembled and written back into
another file by chunk. To achieve this, we require two context managers: one
for reading the input file and another for writing the output file.</p><p>Here&rsquo;s how you would typically do it:</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#b6a0ff>import</span> laspy
</span></span><span style=display:flex><span><span style=color:#b6a0ff>import</span> numpy <span style=color:#b6a0ff>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a8a8a8># reading the file</span>
</span></span><span style=display:flex><span><span style=color:#b6a0ff>with</span> laspy<span style=color:#00d3d0>.</span>open(input_file_name, mode<span style=color:#00d3d0>=</span><span style=color:#79a8ff>&#34;r&#34;</span>) <span style=color:#b6a0ff>as</span> f:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a8a8a8># creating a file</span>
</span></span><span style=display:flex><span>    <span style=color:#b6a0ff>with</span> laspy<span style=color:#00d3d0>.</span>open(output_file_name, mode<span style=color:#00d3d0>=</span><span style=color:#79a8ff>&#34;w&#34;</span>, header<span style=color:#00d3d0>=</span>header) <span style=color:#b6a0ff>as</span> o_f:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#a8a8a8># iteration over the chunk iterator</span>
</span></span><span style=display:flex><span>        <span style=color:#b6a0ff>for</span> chunk <span style=color:#00d3d0>in</span> f<span style=color:#00d3d0>.</span>chunk_iterator(chunk_size):
</span></span><span style=display:flex><span>            <span style=color:#a8a8a8># Normals calculation over each chunk</span>
</span></span><span style=display:flex><span>            point_record <span style=color:#00d3d0>=</span> calculate_normals(chunk)
</span></span><span style=display:flex><span>            <span style=color:#a8a8a8># writting or appending the data into the point cloud</span>
</span></span><span style=display:flex><span>            o_f<span style=color:#00d3d0>.</span>append_points(point_record)
</span></span></code></pre></div><p>To parallelize this process, we create a <code>ProcessPoolExecutor</code> that allows us
to send each execution of the function (where we calculate the normals) to a
separate process. As the processes complete, we collect the results and write
them to the new LAS/LAZ file.</p><p>Since we collect the results of the futures in our main process and then write
them to the file, we avoid issues where multiple processes access the same file
simultaneously. If your implementation does not permit this approach, you may
need to use a <code>lock</code> to ensure data integrity.</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#b6a0ff>import</span> laspy
</span></span><span style=display:flex><span><span style=color:#b6a0ff>import</span> numpy <span style=color:#b6a0ff>as</span> np
</span></span><span style=display:flex><span><span style=color:#b6a0ff>import</span> concurrent.futures
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a8a8a8># reading the file</span>
</span></span><span style=display:flex><span><span style=color:#b6a0ff>with</span> laspy<span style=color:#00d3d0>.</span>open(input_file_name, mode<span style=color:#00d3d0>=</span><span style=color:#79a8ff>&#34;r&#34;</span>) <span style=color:#b6a0ff>as</span> f:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a8a8a8># creating an output file</span>
</span></span><span style=display:flex><span>    <span style=color:#b6a0ff>with</span> laspy<span style=color:#00d3d0>.</span>open(output_file_name, mode<span style=color:#00d3d0>=</span><span style=color:#79a8ff>&#34;w&#34;</span>, header<span style=color:#00d3d0>=</span>f<span style=color:#00d3d0>.</span>header) <span style=color:#b6a0ff>as</span> o_f:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#a8a8a8># this is where we are going to collect our future objects</span>
</span></span><span style=display:flex><span>        futures <span style=color:#00d3d0>=</span> []
</span></span><span style=display:flex><span>        <span style=color:#b6a0ff>with</span> concurrent<span style=color:#00d3d0>.</span>futures<span style=color:#00d3d0>.</span>ProcessPoolExecutor() <span style=color:#b6a0ff>as</span> executor:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#a8a8a8># iteration over the chunk iterator</span>
</span></span><span style=display:flex><span>            <span style=color:#b6a0ff>for</span> chunk <span style=color:#00d3d0>in</span> f<span style=color:#00d3d0>.</span>chunk_iterator(chunk_size):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>                <span style=color:#a8a8a8># disecting the chunk into the points that conform it</span>
</span></span><span style=display:flex><span>                points: np<span style=color:#00d3d0>.</span>ndarray <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>array(
</span></span><span style=display:flex><span>                    (
</span></span><span style=display:flex><span>                        (chunk<span style=color:#00d3d0>.</span>x <span style=color:#00d3d0>+</span> f<span style=color:#00d3d0>.</span>header<span style=color:#00d3d0>.</span>offsets[<span style=color:#00bcff>0</span>])<span style=color:#00d3d0>/</span>f<span style=color:#00d3d0>.</span>header<span style=color:#00d3d0>.</span>scales[<span style=color:#00bcff>0</span>],
</span></span><span style=display:flex><span>                        (chunk<span style=color:#00d3d0>.</span>y <span style=color:#00d3d0>+</span> f<span style=color:#00d3d0>.</span>header<span style=color:#00d3d0>.</span>offsets[<span style=color:#00bcff>1</span>])<span style=color:#00d3d0>/</span>f<span style=color:#00d3d0>.</span>header<span style=color:#00d3d0>.</span>scales[<span style=color:#00bcff>1</span>],
</span></span><span style=display:flex><span>                        (chunk<span style=color:#00d3d0>.</span>z <span style=color:#00d3d0>+</span> f<span style=color:#00d3d0>.</span>header<span style=color:#00d3d0>.</span>offsets[<span style=color:#00bcff>2</span>])<span style=color:#00d3d0>/</span>f<span style=color:#00d3d0>.</span>header<span style=color:#00d3d0>.</span>scales[<span style=color:#00bcff>2</span>],
</span></span><span style=display:flex><span>                    )
</span></span><span style=display:flex><span>                )<span style=color:#00d3d0>.</span>T
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>                <span style=color:#a8a8a8># calculate the normals  in a multi processing pool</span>
</span></span><span style=display:flex><span>                future <span style=color:#00d3d0>=</span> executor<span style=color:#00d3d0>.</span>submit(
</span></span><span style=display:flex><span>                    process_points,   <span style=color:#a8a8a8># function where we calculate the normals</span>
</span></span><span style=display:flex><span>                    points<span style=color:#00d3d0>=</span>points,
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                futures<span style=color:#00d3d0>.</span>append(future)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#a8a8a8># awaiting all the future to complete in case we needed</span>
</span></span><span style=display:flex><span>        <span style=color:#b6a0ff>for</span> future <span style=color:#00d3d0>in</span> concurrent<span style=color:#00d3d0>.</span>futures<span style=color:#00d3d0>.</span>as_completed(futures):
</span></span><span style=display:flex><span>            <span style=color:#a8a8a8># unpacking the result from the future</span>
</span></span><span style=display:flex><span>            result <span style=color:#00d3d0>=</span> future<span style=color:#00d3d0>.</span>result()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#a8a8a8># creating a point record to store the results</span>
</span></span><span style=display:flex><span>            point_record <span style=color:#00d3d0>=</span> laspy<span style=color:#00d3d0>.</span>PackedPointRecord<span style=color:#00d3d0>.</span>empty(
</span></span><span style=display:flex><span>                point_format<span style=color:#00d3d0>=</span>f<span style=color:#00d3d0>.</span>header<span style=color:#00d3d0>.</span>point_format
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#a8a8a8># appending information to that point record</span>
</span></span><span style=display:flex><span>            point_record<span style=color:#00d3d0>.</span>array <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>append(
</span></span><span style=display:flex><span>                point_record<span style=color:#00d3d0>.</span>array,
</span></span><span style=display:flex><span>                result
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#a8a8a8># appending the point record into the point cloud</span>
</span></span><span style=display:flex><span>            o_f<span style=color:#00d3d0>.</span>append_points(point_record)
</span></span></code></pre></div><p>There are a lot of things to unpack from this code, like <em>why are we not using
the chunk object itself?</em>, <em>why we are creating an empty <code>PackedPointRecord</code>?</em>.</p><p>We will start with the <code>chunk</code> object. Without touching the why, the object
itself cannot be send to be processed in a process pool. Because of that, we
have to pull the information that we find important from it. Because we are
calculating the normals, what we need are the X, Y and Z coordinates of the
Chunk, taking into account the offset and the scale specified in the header of
the LAS/LAZ file.</p><p>Given that the calculations return us an array of values, that will represent
the X,Y and Z coordinates, the RGB values, The intensity and the
classification, we cannot write that directly into the LAS/LAZ file, we need to
create a <code>PackedPointRecord</code> with the format specified in the header, on which
we will store the returned array, and then append them to the LAS/LAZ file.</p><p>The LAS/LAZ file, has a header object, on which we store the scale, the offset
and the format of the Point Cloud. This is important because for us to be able
to send information to that file, the format of our values must match the one
specified in the header. In our case, both files have the same header format.
However, if you need to write to files with different versions, the array
format must match the version you are writing to.</p><p>To identify the format required to be able to append the results into the
<code>PackedPointRecord</code>, you could run the following command,</p><pre tabindex=0><code class=language-log data-lang=log>&gt;&gt;&gt; f.header.point_format.dtype()
</code></pre><p>In this example, we are using Point Format version 3, which has the following
structure:</p><pre tabindex=0><code class=language-log data-lang=log>np.dtype([
    (&#39;X&#39;, np.int32),
    (&#39;Y&#39;, np.int32),
    (&#39;Z&#39;, np.int32),
    (&#39;intensity&#39;, np.int16),
    (&#39;bit_fields&#39;, np.uint8),
    (&#39;raw_classification&#39;, np.uint8),
    (&#39;scan_angle_rank&#39;, np.uint8),
    (&#39;user_data&#39;, np.uint8),
    (&#39;point_source_id&#39;, np.int16),
    (&#39;gps_time&#39;, np.float64),
    (&#39;red&#39;, np.int16),
    (&#39;green&#39;, np.int16),
    (&#39;blue&#39;, np.int16),
])
</code></pre><p>Because we couldn&rsquo;t use this command, to match the dtype of the unpacked future
to the dtype of the header.</p><pre tabindex=0><code class=language-log data-lang=log>&gt;&gt;&gt; result = result.astype(header.point_format.dtype())
</code></pre><p>we had to do the transformation in the following manner,</p><div class=highlight><pre tabindex=0 style=color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#b6a0ff>def</span> <span style=color:#feacd0>process_points</span>(
</span></span><span style=display:flex><span>    points: np<span style=color:#00d3d0>.</span>ndarray,
</span></span><span style=display:flex><span>) <span style=color:#00d3d0>-&gt;</span> np<span style=color:#00d3d0>.</span>ndarray:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a8a8a8># normals calculation</span>
</span></span><span style=display:flex><span>    normals, curvature, density <span style=color:#00d3d0>=</span> calculate_normals(points<span style=color:#00d3d0>=</span>points)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a8a8a8># RGB</span>
</span></span><span style=display:flex><span>    red, green, blue <span style=color:#00d3d0>=</span> <span style=color:#00bcff>255</span> <span style=color:#00d3d0>*</span> (np<span style=color:#00d3d0>.</span>abs(normals))<span style=color:#00d3d0>.</span>T
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    dtype <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>dtype([
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;X&#39;</span>, np<span style=color:#00d3d0>.</span>int32),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;Y&#39;</span>, np<span style=color:#00d3d0>.</span>int32),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;Z&#39;</span>, np<span style=color:#00d3d0>.</span>int32),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;intensity&#39;</span>, np<span style=color:#00d3d0>.</span>int16),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;bit_fields&#39;</span>, np<span style=color:#00d3d0>.</span>uint8),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;raw_classification&#39;</span>, np<span style=color:#00d3d0>.</span>uint8),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;scan_angle_rank&#39;</span>, np<span style=color:#00d3d0>.</span>uint8),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;user_data&#39;</span>, np<span style=color:#00d3d0>.</span>uint8),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;point_source_id&#39;</span>, np<span style=color:#00d3d0>.</span>int16),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;gps_time&#39;</span>, np<span style=color:#00d3d0>.</span>float64),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;red&#39;</span>, np<span style=color:#00d3d0>.</span>int16),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;green&#39;</span>, np<span style=color:#00d3d0>.</span>int16),
</span></span><span style=display:flex><span>        (<span style=color:#79a8ff>&#39;blue&#39;</span>, np<span style=color:#00d3d0>.</span>int16),
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    array <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>zeros(<span style=color:#f78fe7>len</span>(points), dtype<span style=color:#00d3d0>=</span>dtype)
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;X&#39;</span>] <span style=color:#00d3d0>=</span> points[:, <span style=color:#00bcff>0</span>]
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;Y&#39;</span>] <span style=color:#00d3d0>=</span> points[:, <span style=color:#00bcff>1</span>]
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;Z&#39;</span>] <span style=color:#00d3d0>=</span> points[:, <span style=color:#00bcff>2</span>]
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;intensity&#39;</span>] <span style=color:#00d3d0>=</span> density
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;bit_fields&#39;</span>] <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>zeros(<span style=color:#f78fe7>len</span>(points), dtype<span style=color:#00d3d0>=</span>np<span style=color:#00d3d0>.</span>uint8)
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;raw_classification&#39;</span>] <span style=color:#00d3d0>=</span> curvature
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;scan_angle_rank&#39;</span>] <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>zeros(<span style=color:#f78fe7>len</span>(points), dtype<span style=color:#00d3d0>=</span>np<span style=color:#00d3d0>.</span>uint8)
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;user_data&#39;</span>] <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>zeros(<span style=color:#f78fe7>len</span>(points), dtype<span style=color:#00d3d0>=</span>np<span style=color:#00d3d0>.</span>uint8)
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;point_source_id&#39;</span>] <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>zeros(<span style=color:#f78fe7>len</span>(points), dtype<span style=color:#00d3d0>=</span>np<span style=color:#00d3d0>.</span>int16)
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;gps_time&#39;</span>] <span style=color:#00d3d0>=</span> np<span style=color:#00d3d0>.</span>zeros(<span style=color:#f78fe7>len</span>(points), dtype<span style=color:#00d3d0>=</span>np<span style=color:#00d3d0>.</span>float64)
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;red&#39;</span>] <span style=color:#00d3d0>=</span> red
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;green&#39;</span>] <span style=color:#00d3d0>=</span> green
</span></span><span style=display:flex><span>    array[<span style=color:#79a8ff>&#39;blue&#39;</span>] <span style=color:#00d3d0>=</span> blue
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#b6a0ff>return</span> np<span style=color:#00d3d0>.</span>ascontiguousarray(array)
</span></span></code></pre></div><p>And with all of this put together, we are able to process large Point Clouds in
parallel, using all the resources of our computer.</p><p>Even tho is needed a great deal of familiarity with the mentioned packages to
understand and apply the code above, the idea was to tackle one of the common
problems that we have encountered with the processing of our Point Clouds and
share the solutions that we have found for our problems.</p><p>In case there is something else needed to be discussed, like a better approach
or if you have doubts and want to know more about the code, don&rsquo;t be afraid to
contact me, I will gladly help in what I can.</p></p><b>Tags:</b>
python, LAS, LAZ, PointCloud, LiDAR</div></main><footer class="footer mt-auto py-3 fixed-bottom"><div class=container-fluid style=text-align:center><div class="d-flex gap-4 justify-content-center"><a href=mailto:jacobobedoya@gmail.com style=text-decoration:none><svg style="height:2rem;width:auto" fill="#000" class="bi bi-mailbox" viewBox="0 0 16 16"><path d="M4 4A3 3 0 001 7v6h6V7A3 3 0 004 4zm0-1h8a4 4 0 014 4v6a1 1 0 01-1 1H1a1 1 0 01-1-1V7a4 4 0 014-4zm2.646 1A3.99 3.99.0 018 7v6h7V7a3 3 0 00-3-3H6.646z"/><path d="M11.793 8.5H9v-1h5a.5.5.0 01.5.5v1a.5.5.0 01-.5.5h-1a.5.5.0 01-.354-.146l-.853-.854zM5 7c0 .552-.448.0-1 0s-1 .552-1 0a1 1 0 012 0z"/></svg>
</a><a href=https://www.instagram.com/jacobitosuperstar/ style=text-decoration:none><svg style="height:1.5rem;width:auto" class="bi bi-instagram" viewBox="0 0 16 16" fill="#00fa9a" onmouseover="this.style.fill='mediumturquoise'" onmouseout="this.style.fill='mediumspringgreen'"><path d="M8 0C5.829.0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917.0 00-1.417.923A3.927 3.927.0 00.42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555.0 5.827.0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916.0 001.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926.0 00-.923-1.417A3.911 3.911.0 0013.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172.0 7.998.0h.003zm-.717 1.442h.718c2.136.0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47.0 01-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478.0 01-.92-.598 2.48 2.48.0 01-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233.0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96.0 100 1.92.96.96.0 000-1.92zm-4.27 1.122a4.109 4.109.0 100 8.217 4.109 4.109.0 000-8.217zm0 1.441a2.667 2.667.0 110 5.334 2.667 2.667.0 010-5.334z"/></svg>
</a><a href=https://github.com/jacobitosuperstar style=text-decoration:none><svg style="height:1.5rem;width:auto" class="bi bi-github" viewBox="0 0 16 16" fill="#00fa9a" onmouseover="this.style.fill='mediumturquoise'" onmouseout="this.style.fill='mediumspringgreen'"><path d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.012 8.012.0 0016 8c0-4.42-3.58-8-8-8z"/></svg>
</a><a href=https://www.linkedin.com/in/jacobo-mateo-bedoya-oquendo-233a46202/ style=text-decoration:none><svg style="height:1.5rem;width:auto" class="bi bi-linkedin" viewBox="0 0 16 16" fill="#00fa9a" onmouseover="this.style.fill='mediumturquoise'" onmouseout="this.style.fill='mediumspringgreen'"><path d="M0 1.146C0 .513.526.0 1.175.0h13.65C15.474.0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487.0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837.0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822.0-1.359.54-1.359 1.248.0.694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869.0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274.0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54.0 01.016-.025V6.169h-2.4c.03.678.0 7.225.0 7.225h2.4z"/></svg></a></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js integrity=sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r crossorigin=anonymous></script></body></html>